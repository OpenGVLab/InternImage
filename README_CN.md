<p>
	<a href="./README.md">[English Version]</a>
</p>

# ä¹¦ç”Ÿå›¾åƒ - å¤§è§„æ¨¡è§†è§‰åŸºç¡€æ¨¡å‹

[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/object-detection-on-coco)](https://paperswithcode.com/sota/object-detection-on-coco?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/object-detection-on-coco-minival)](https://paperswithcode.com/sota/object-detection-on-coco-minival?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/object-detection-on-lvis-v1-0-minival)](https://paperswithcode.com/sota/object-detection-on-lvis-v1-0-minival?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/object-detection-on-lvis-v1-0-val)](https://paperswithcode.com/sota/object-detection-on-lvis-v1-0-val?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/object-detection-on-pascal-voc-2012)](https://paperswithcode.com/sota/object-detection-on-pascal-voc-2012?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/object-detection-on-openimages-v6)](https://paperswithcode.com/sota/object-detection-on-openimages-v6?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/object-detection-on-crowdhuman-full-body)](https://paperswithcode.com/sota/object-detection-on-crowdhuman-full-body?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/2d-object-detection-on-bdd100k-val)](https://paperswithcode.com/sota/2d-object-detection-on-bdd100k-val?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/semantic-segmentation-on-ade20k)](https://paperswithcode.com/sota/semantic-segmentation-on-ade20k?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/semantic-segmentation-on-cityscapes)](https://paperswithcode.com/sota/semantic-segmentation-on-cityscapes?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/semantic-segmentation-on-cityscapes-val)](https://paperswithcode.com/sota/semantic-segmentation-on-cityscapes-val?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/semantic-segmentation-on-pascal-context)](https://paperswithcode.com/sota/semantic-segmentation-on-pascal-context?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/image-classification-on-inaturalist-2018)](https://paperswithcode.com/sota/image-classification-on-inaturalist-2018?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/image-classification-on-places365)](https://paperswithcode.com/sota/image-classification-on-places365?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/image-classification-on-places205)](https://paperswithcode.com/sota/image-classification-on-places205?p=internimage-exploring-large-scale-vision)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/bevformer-v2-adapting-modern-image-backbones/3d-object-detection-on-nuscenes-camera-only)](https://paperswithcode.com/sota/3d-object-detection-on-nuscenes-camera-only?p=bevformer-v2-adapting-modern-image-backbones)
[![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/internimage-exploring-large-scale-vision/image-classification-on-imagenet)](https://paperswithcode.com/sota/image-classification-on-imagenet?p=internimage-exploring-large-scale-vision)

è¿™ä¸ªä»£ç ä»“åº“æ˜¯ [InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions](https://arxiv.org/abs/2211.05778) çš„å®˜æ–¹å®ç°ã€‚

\[[è®ºæ–‡](https://arxiv.org/abs/2211.05778)\] \[[çŸ¥ä¹ä¸“æ ](https://zhuanlan.zhihu.com/p/610772005)\]

## äº®ç‚¹

- :thumbsup: **é«˜è¾¾ 30 äº¿å‚æ•°çš„æœ€å¼ºè§†è§‰é€šç”¨ä¸»å¹²æ¨¡å‹**
- ğŸ† **å›¾åƒåˆ†ç±»æ ‡æ†æ•°æ®é›† ImageNet `90.1% Top1`å‡†ç¡®ç‡ï¼Œå¼€æºæ¨¡å‹ä¸­å‡†ç¡®åº¦æœ€é«˜**
- ğŸ† **ç‰©ä½“æ£€æµ‹æ ‡æ†æ•°æ®é›† COCO `65.5 mAP`ï¼Œå”¯ä¸€è¶…è¿‡ `65 mAP` çš„æ¨¡å‹**

## æœ€æ–°è¿›å±•

- 2024å¹´1æœˆ22æ—¥: ğŸš€ åœ¨ InternImage ä¸­æ”¯æŒäº† [DCNv4](https://github.com/OpenGVLab/DCNv4)!
- 2023å¹´2æœˆ28æ—¥: ğŸš€ InternImage è¢« CVPR 2023 æ¥æ”¶!
- 2022å¹´11æœˆ18æ—¥: ğŸš€ åŸºäº InternImage-XL ä¸»å¹²ç½‘ç»œï¼Œ[BEVFormer v2](https://arxiv.org/abs/2211.10439) åœ¨nuScenesçš„çº¯è§†è§‰3Dæ£€æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†æœ€ä½³æ€§èƒ½ `63.4 NDS` ï¼
- 2022å¹´11æœˆ10æ—¥: ğŸš€ InternImage-H åœ¨ COCO ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸Šä»¥ `65.4 mAP` æ–©è·å† å†›ï¼Œæ˜¯å”¯ä¸€çªç ´ `65.0 mAP` çš„è¶…å¼ºç‰©ä½“æ£€æµ‹æ¨¡å‹ï¼
- 2022å¹´11æœˆ10æ—¥: ğŸš€ InternImage-H åœ¨ ADE20K è¯­ä¹‰åˆ†å‰²æ•°æ®é›†ä¸Šå–å¾— `62.9 mIoU` çš„SOTAæ€§èƒ½ï¼

## é¡¹ç›®åŠŸèƒ½

- [ ] å„ç±»ä¸‹æ¸¸ä»»åŠ¡
- [ ] æ”¯æŒ [CVPR 2023 Workshop on End-to-End Autonomous Driving](https://opendrivelab.com/e2ead/cvpr23)ï¼Œ[è¯¦è§](https://github.com/OpenGVLab/InternImage/tree/master/autonomous_driving)
- [x] æ”¯æŒæå–æ¨¡å‹ä¸­é—´å±‚ç‰¹å¾ï¼Œ[è¯¦è§](classification/extract_feature.py)
- [x] æ”¯æŒåŸºäº [DeepSpeed](https://github.com/microsoft/DeepSpeed) çš„ä½æˆæœ¬è®­ç»ƒï¼Œ[è¯¦è§](https://github.com/OpenGVLab/InternImage/tree/master/classification)
- [x] DCNv3 ç®—å­é¢„ç¼–è¯‘ `.whl` åŒ…ï¼Œ[è¯¦è§](https://github.com/OpenGVLab/InternImage/releases/tag/whl_files)
- [x] InternImage-H(1B)/G(3B)
- [x] æ”¯æŒåˆ†ç±»/æ£€æµ‹/åˆ†å‰² TensorRT æ¨ç†
- [x] InternImage ç³»åˆ—åˆ†ç±»ä»£ç 
- [x] InternImage-T/S/B/L/XL ImageNet-1K é¢„è®­ç»ƒæ¨¡å‹
- [x] InternImage-L/XL ImageNet-22K é¢„è®­ç»ƒæ¨¡å‹
- [x] InternImage-T/S/B/L/XL æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²æ¨¡å‹
- [x] InternImage-T/S/B/L/XL è¯­ä¹‰åˆ†å‰²æ¨¡å‹

## ç®€ä»‹

InternImage æ˜¯ä¸€ä¸ªç”±ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤ã€æ¸…åå¤§å­¦ç­‰æœºæ„çš„ç ”ç©¶äººå‘˜æå‡ºçš„åŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰çš„è§†è§‰åŸºç¡€æ¨¡å‹ã€‚ä¸åŸºäº Transformer çš„ç½‘ç»œä¸åŒï¼ŒInternImage ä»¥å¯å˜å½¢å·ç§¯ DCNv3 ä½œä¸ºæ ¸å¿ƒç®—å­ï¼Œä½¿æ¨¡å‹ä¸ä»…å…·æœ‰æ£€æµ‹å’Œåˆ†å‰²ç­‰ä¸‹æ¸¸ä»»åŠ¡æ‰€éœ€çš„åŠ¨æ€æœ‰æ•ˆæ„Ÿå—é‡ï¼Œè€Œä¸”èƒ½å¤Ÿè¿›è¡Œè‡ªé€‚åº”çš„ç©ºé—´èšåˆã€‚

<div align=center>
<img src='./docs/figs/arch.png' width=400>
</div>

ä¸ InternImage ç›¸å…³çš„å…¶ä»–é¡¹ç›®è¿˜åŒ…æ‹¬ï¼šé¢„è®­ç»ƒç®—æ³• M3I-Pretrainingï¼Œé€šç”¨è§£ç å™¨ Uni-Perceiver ç³»åˆ—ï¼Œä»¥åŠè‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥é€šç”¨ç¼–ç å™¨ BEVFormer ç³»åˆ—ã€‚

<div align=left>
<img src='./docs/figs/intern_pipeline.png' width=900>
</div>

## æ€§èƒ½

- åœ¨å›¾åƒåˆ†ç±»æ ‡æ†æ•°æ®é›† ImageNet ä¸Šï¼ŒInternImage ä»…åŸºäºå…¬å¼€æ•°æ®ä¾¿è¾¾åˆ°äº† 90.1% çš„ Top-1 å‡†ç¡®ç‡ã€‚è¿™æ˜¯é™¤è°·æ­Œä¸å¾®è½¯ä¸¤ä¸ªæœªå…¬å¼€æ¨¡å‹åŠé¢å¤–æ•°æ®é›†å¤–ï¼Œå”¯ä¸€å‡†ç¡®ç‡è¶…è¿‡ 90.0% çš„æ¨¡å‹ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸–ç•Œä¸Šå¼€æºæ¨¡å‹ä¸­ ImageNet å‡†ç¡®åº¦æœ€é«˜ï¼Œè§„æ¨¡æœ€å¤§çš„æ¨¡å‹ï¼›
- åœ¨ç‰©ä½“æ£€æµ‹æ ‡æ†æ•°æ®é›† COCO ä¸Šï¼ŒInternImage å–å¾—äº† 65.5 çš„ mAPï¼Œæ˜¯ä¸–ç•Œä¸Šå”¯ä¸€è¶…è¿‡ 65 mAP çš„æ¨¡å‹ï¼›
- åœ¨å¦å¤– 16 ä¸ªé‡è¦çš„è§†è§‰åŸºç¡€æ•°æ®é›†ï¼ˆè¦†ç›–åˆ†ç±»ã€æ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡ï¼‰ä¸Šå–å¾—ä¸–ç•Œæœ€å¥½æ€§èƒ½ã€‚

**åˆ†ç±»ä»»åŠ¡**

<table border="1" width="90%">
	<tr align="center">
        <th colspan="1"> å›¾åƒåˆ†ç±» </th><th colspan="2"> åœºæ™¯åˆ†ç±» </th><th colspan="1"> é•¿å°¾åˆ†ç±» </th>
    </tr>
    <tr align="center">
        <th>ImageNet</th><th>Places365</th><th>Places 205</th><th>iNaturalist 2018</th>
    </tr>
    <tr align="center">
        <th>90.1</th><th>61.2</th><th>71.7</th><th>92.6</th>
    </tr>
</table>

**æ£€æµ‹ä»»åŠ¡**

<table border="1" width="90%">
	<tr align="center">
        <th colspan="4"> å¸¸è§„ç‰©ä½“æ£€æµ‹ </th><th colspan="2"> é•¿å°¾ç‰©ä½“æ£€æµ‹ </th><th colspan="2"> è‡ªåŠ¨é©¾é©¶ç‰©ä½“æ£€æµ‹ </th><th colspan="1"> å¯†é›†ç‰©ä½“æ£€æµ‹ </th>
    </tr>
    <tr align="center">
        <th>COCO</th><th>VOC 2007</th><th>VOC 2012</th><th>OpenImage</th><th>LVIS minival</th><th>LVIS val</th><th>BDD100K</th><th>nuScenes</th><th>CrowdHuman</th>
    </tr>
    <tr align="center">
        <th>65.5</th><th>94.0</th><th>97.2</th><th>74.1</th><th>65.8</th><th>63.2</th><th>38.8</th><th>64.8</th><th>97.2</th>
    </tr>
</table>

**åˆ†å‰²ä»»åŠ¡**

<table border="1" width="90%">
	<tr align="center">
        <th colspan="3">è¯­ä¹‰åˆ†å‰²</th><th colspan="1">è¡—æ™¯åˆ†å‰²</th><th colspan="1">RGBDåˆ†å‰²</th>
    </tr>
    <tr align="center">
        <th>ADE20K</th><th>COCO Stuff-10K</th><th>Pascal Context</th><th>CityScapes</th><th>NYU Depth V2</th>
    </tr>
    <tr align="center">
        <th>62.9</th><th>59.6</th><th>70.3</th><th>87.0</th><th>68.1</th>
    </tr>
</table>

## å·²å‘å¸ƒæ¨¡å‹

<details open>
<summary> å¼€æºè§†è§‰é¢„è®­ç»ƒæ¨¡å‹ </summary>
<br>
<div>

|      name      |   pretrain   | resolution | #param |                                               download                                                |
| :------------: | :----------: | :--------: | :----: | :---------------------------------------------------------------------------------------------------: |
| InternImage-L  | ImageNet-22K |  384x384   |  223M  |   [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_l_22k_192to384.pth)    |
| InternImage-XL | ImageNet-22K |  384x384   |  335M  |   [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_xl_22k_192to384.pth)   |
| InternImage-H  |  Joint 427M  |  384x384   | 1.08B  |  [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_h_jointto22k_384.pth)   |
| InternImage-G  |  Joint 427M  |  384x384   |   3B   | [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_g_pretrainto22k_384.pth) |

</div>

</details>

<details open>
<summary> ImageNet-1K å›¾åƒåˆ†ç±» </summary>
<br>
<div>

|      name      |   pretrain   | resolution | acc@1 | #param | FLOPs |                                                                              download                                                                               |
| :------------: | :----------: | :--------: | :---: | :----: | :---: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| InternImage-T  | ImageNet-1K  |  224x224   | 83.5  |  30M   |  5G   |       [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_t_1k_224.pth) \| [cfg](configs/without_lr_decay/internimage_t_1k_224.yaml)       |
| InternImage-S  | ImageNet-1K  |  224x224   | 84.2  |  50M   |  8G   |       [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth) \| [cfg](configs/without_lr_decay/internimage_s_1k_224.yaml)       |
| InternImage-B  | ImageNet-1K  |  224x224   | 84.9  |  97M   |  16G  |       [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_b_1k_224.pth) \| [cfg](configs/without_lr_decay/internimage_b_1k_224.yaml)       |
| InternImage-L  | ImageNet-22K |  384x384   | 87.7  |  223M  | 108G  |  [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_l_22kto1k_384.pth) \| [cfg](configs/without_lr_decay/internimage_l_22kto1k_384.yaml)  |
| InternImage-XL | ImageNet-22K |  384x384   | 88.0  |  335M  | 163G  | [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_xl_22kto1k_384.pth) \| [cfg](configs/without_lr_decay/internimage_xl_22kto1k_384.yaml) |
| InternImage-H  |  Joint 427M  |  640x640   | 89.6  | 1.08B  | 1478G |  [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_h_22kto1k_640.pth) \| [cfg](configs/without_lr_decay/internimage_h_22kto1k_640.yaml)  |
| InternImage-G  |  Joint 427M  |  512x512   | 90.1  |   3B   | 2700G |  [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_g_22kto1k_512.pth) \| [cfg](configs/without_lr_decay/internimage_g_22kto1k_512.yaml)  |

</div>

</details>

<details open>
<summary> COCO ç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰² </summary>
<br>
<div>

|    backbone    |   method   | schd | box mAP | mask mAP | #param | FLOPs |                                                                                     download                                                                                      |
| :------------: | :--------: | :--: | :-----: | :------: | :----: | :---: | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| InternImage-T  | Mask R-CNN |  1x  |  47.2   |   42.5   |  49M   | 270G  | [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/mask_rcnn_internimage_t_fpn_1x_coco.pth) \| [cfg](detection/configs/coco/mask_rcnn_internimage_t_fpn_1x_coco.py) |
| InternImage-T  | Mask R-CNN |  3x  |  49.1   |   43.7   |  49M   | 270G  | [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/mask_rcnn_internimage_t_fpn_3x_coco.pth) \| [cfg](detection/configs/coco/mask_rcnn_internimage_t_fpn_3x_coco.py) |
| InternImage-S  | Mask R-CNN |  1x  |  47.8   |   43.3   |  69M   | 340G  | [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/mask_rcnn_internimage_s_fpn_1x_coco.pth) \| [cfg](detection/configs/coco/mask_rcnn_internimage_s_fpn_1x_coco.py) |
| InternImage-S  | Mask R-CNN |  3x  |  49.7   |   44.5   |  69M   | 340G  | [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/mask_rcnn_internimage_s_fpn_3x_coco.pth) \| [cfg](detection/configs/coco/mask_rcnn_internimage_s_fpn_3x_coco.py) |
| InternImage-B  | Mask R-CNN |  1x  |  48.8   |   44.0   |  115M  | 501G  | [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/mask_rcnn_internimage_b_fpn_1x_coco.pth) \| [cfg](detection/configs/coco/mask_rcnn_internimage_b_fpn_1x_coco.py) |
| InternImage-B  | Mask R-CNN |  3x  |  50.3   |   44.8   |  115M  | 501G  | [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/mask_rcnn_internimage_b_fpn_3x_coco.pth) \| [cfg](detection/configs/coco/mask_rcnn_internimage_b_fpn_3x_coco.py) |
| InternImage-L  |  Cascade   |  1x  |  54.9   |   47.7   |  277M  | 1399G |   [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/cascade_internimage_l_fpn_1x_coco.pth) \| [cfg](detection/configs/coco/cascade_internimage_l_fpn_1x_coco.py)   |
| InternImage-L  |  Cascade   |  3x  |  56.1   |   48.5   |  277M  | 1399G |   [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/cascade_internimage_l_fpn_3x_coco.pth) \| [cfg](detection/configs/coco/cascade_internimage_l_fpn_3x_coco.py)   |
| InternImage-XL |  Cascade   |  1x  |  55.3   |   48.1   |  387M  | 1782G |  [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/cascade_internimage_xl_fpn_1x_coco.pth) \| [cfg](detection/configs/coco/cascade_internimage_xl_fpn_1x_coco.py)  |
| InternImage-XL |  Cascade   |  3x  |  56.2   |   48.8   |  387M  | 1782G |  [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/cascade_internimage_xl_fpn_3x_coco.pth) \| [cfg](detection/configs/coco/cascade_internimage_xl_fpn_3x_coco.py)  |

|   backbone    |   method   | box mAP (val/test) | #param | FLOPs | download |
| :-----------: | :--------: | :----------------: | :----: | :---: | :------: |
| InternImage-H | DINO (TTA) |    65.0 / 65.4     | 2.18B  | TODO  |   TODO   |
| InternImage-G | DINO (TTA) |    65.3 / 65.5     |   3B   | TODO  |   TODO   |

</div>

</details>

<details open>
<summary> ADE20K è¯­ä¹‰åˆ†å‰² </summary>
<br>
<div>

|    backbone    |   method    | resolution | mIoU (ss/ms) | #param | FLOPs |                                                                                                        download                                                                                                         |
| :------------: | :---------: | :--------: | :----------: | :----: | :---: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| InternImage-T  |   UperNet   |  512x512   | 47.9 / 48.1  |  59M   | 944G  |               [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/upernet_internimage_t_512_160k_ade20k.pth) \| [cfg](segmentation/configs/ade20k/upernet_internimage_t_512_160k_ade20k.py)                |
| InternImage-S  |   UperNet   |  512x512   | 50.1 / 50.9  |  80M   | 1017G |               [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/upernet_internimage_s_512_160k_ade20k.pth) \| [cfg](segmentation/configs/ade20k/upernet_internimage_s_512_160k_ade20k.py)                |
| InternImage-B  |   UperNet   |  512x512   | 50.8 / 51.3  |  128M  | 1185G |               [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/upernet_internimage_b_512_160k_ade20k.pth) \| [cfg](segmentation/configs/ade20k/upernet_internimage_b_512_160k_ade20k.py)                |
| InternImage-L  |   UperNet   |  640x640   | 53.9 / 54.1  |  256M  | 2526G |               [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/upernet_internimage_l_640_160k_ade20k.pth) \| [cfg](segmentation/configs/ade20k/upernet_internimage_l_640_160k_ade20k.py)                |
| InternImage-XL |   UperNet   |  640x640   | 55.0 / 55.3  |  368M  | 3142G |              [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/upernet_internimage_xl_640_160k_ade20k.pth) \| [cfg](segmentation/configs/ade20k/upernet_internimage_xl_640_160k_ade20k.py)               |
| InternImage-H  |   UperNet   |  896x896   | 59.9 / 60.3  | 1.12B  | 3566G |               [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/upernet_internimage_h_896_160k_ade20k.pth) \| [cfg](segmentation/configs/ade20k/upernet_internimage_h_896_160k_ade20k.py)                |
| InternImage-H  | Mask2Former |  896x896   | 62.5 / 62.9  | 1.31B  | 4635G | [ckpt](https://huggingface.co/OpenGVLab/InternImage/resolve/main/mask2former_internimage_h_896_80k_cocostuff2ade20k.pth) \| [cfg](segmentation/configs/ade20k/mask2former_internimage_h_896_80k_cocostuff2ade20k_ss.py) |

</div>

</details>

<details>
<summary> æ¨¡å‹æ¨ç†é€Ÿåº¦ </summary>
<br>
<div>

[Export classification model from pytorch to tensorrt](classification/README.md#export)

[Export detection model from pytorch to tensorrt](detection/README.md#export)

[Export segmentation model from pytorch to tensorrt](segmentation/README.md#export)

|      name      | resolution | #param | FLOPs | batch 1 FPS (TensorRT) |
| :------------: | :--------: | :----: | :---: | :--------------------: |
| InternImage-T  |  224x224   |  30M   |  5G   |          156           |
| InternImage-S  |  224x224   |  50M   |  8G   |          129           |
| InternImage-B  |  224x224   |  97M   |  16G  |          116           |
| InternImage-L  |  384x384   |  223M  | 108G  |           56           |
| InternImage-XL |  384x384   |  335M  | 163G  |           47           |

åœ¨ä½¿ç”¨ `mmdeploy` å°† PyTorch æ¨¡å‹è½¬ä¸º TensorRT ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²æ­£ç¡®ç¼–è¯‘ DCNv3 çš„è‡ªå®šä¹‰ç®—å­ï¼Œå…¶å®‰è£…æ–¹å¼å¦‚ä¸‹ï¼š

```shell
export MMDEPLOY_DIR=/the/root/path/of/MMDeploy

# prepare our custom ops, you can find it at InternImage/tensorrt/modulated_deform_conv_v3
cp -r modulated_deform_conv_v3 ${MMDEPLOY_DIR}/csrc/mmdeploy/backend_ops/tensorrt

# build custom ops
cd ${MMDEPLOY_DIR}
mkdir -p build && cd build
cmake -DCMAKE_CXX_COMPILER=g++-7 -DMMDEPLOY_TARGET_BACKENDS=trt -DTENSORRT_DIR=${TENSORRT_DIR} -DCUDNN_DIR=${CUDNN_DIR} ..
make -j$(nproc) && make install

# install the mmdeploy after building custom ops
cd ${MMDEPLOY_DIR}
pip install -e .
```

å…³äº `mmdeploy` ç¼–è¯‘è‡ªå®šä¹‰ç®—å­çš„æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚è€ƒè¿™ä»½[æ–‡æ¡£](https://github.com/open-mmlab/mmdeploy/blob/master/docs/en/01-how-to-build/linux-x86_64.md)ã€‚

</div>

</details>

## ç›¸å…³é¡¹ç›®

### å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹

- [Uni-Perceiver](https://github.com/fundamentalvision/Uni-Perceiver): é€šç”¨æ„ŸçŸ¥ä»»åŠ¡é¢„è®­ç»ƒç»Ÿä¸€æ¡†æ¶, å¯ç›´æ¥å¤„ç† zero-shot å’Œ few-shot ä»»åŠ¡
- [Uni-Perceiver v2](https://arxiv.org/abs/2211.09808): ç”¨äºå¤„ç†å›¾åƒ/å›¾æ–‡ä»»åŠ¡çš„é€šç”¨æ¨¡å‹
- [M3I-Pretraining](https://github.com/OpenGVLab/M3I-Pretraining): åŸºäºæœ€å¤§åŒ–è¾“å…¥å’Œç›®æ ‡çš„äº’ä¿¡æ¯çš„å•é˜¶æ®µé¢„è®­ç»ƒèŒƒå¼
- [InternVL](https://github.com/OpenGVLab/InternVL): é¢†å…ˆçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œåœ¨ OCRã€å¤šæ¨¡æ€æ¨ç†å’Œå¯¹è¯ç­‰ä»»åŠ¡ä¸­è¡¨ç°å“è¶Š

### è‡ªåŠ¨é©¾é©¶

- [BEVFormer](https://github.com/fundamentalvision/BEVFormer): åŸºäº BEV çš„æ–°ä¸€ä»£çº¯è§†è§‰ç¯è§†æ„ŸçŸ¥æ–¹æ¡ˆ
- [BEVFormer v2](https://arxiv.org/abs/2211.10439): èåˆ BEV æ„ŸçŸ¥å’Œé€è§†å›¾æ£€æµ‹çš„ä¸¤é˜¶æ®µæ£€æµ‹å™¨

## ç®—æ³•ç«èµ›

- [2022 Waymo 3D Camera-Only Detection Challenge](https://waymo.com/open/challenges/2022/3d-camera-only-detection/): åŸºäº InternImageï¼ŒBEVFormer++ å–å¾—èµ›é“å† å†›
- [nuScenes 3D detection](https://www.nuscenes.org/object-detection?externalData=all&mapData=all&modalities=Camera): BEVFormer v2 åœ¨ nuScenes çº¯è§†è§‰æ£€æµ‹ä»»åŠ¡ä¸­å–å¾—SOTAæ€§èƒ½ (64.8 NDS)
- [CVPR 2023 Workshop End-to-End Autonomous Driving](https://opendrivelab.com/e2ead/cvpr23): InternImage ä½œä¸º baseline æ”¯æŒäº†æ¯”èµ› [3D Occupancy Prediction Challenge](https://opendrivelab.com/AD23Challenge.html#Track3) å’Œ [OpenLane Topology Challenge](https://opendrivelab.com/AD23Challenge.html#Track1)

## å¼•ç”¨

è‹¥è¿™ä¸ªå·¥ä½œå¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å‚è€ƒå¦‚ä¸‹ BibTeX å¯¹æˆ‘ä»¬çš„å·¥ä½œè¿›è¡Œå¼•ç”¨ã€‚

```bibtex
@article{wang2022internimage,
  title={InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions},
  author={Wang, Wenhai and Dai, Jifeng and Chen, Zhe and Huang, Zhenhang and Li, Zhiqi and Zhu, Xizhou and Hu, Xiaowei and Lu, Tong and Lu, Lewei and Li, Hongsheng and others},
  journal={arXiv preprint arXiv:2211.05778},
  year={2022}
}
```
